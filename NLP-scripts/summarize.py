import requests
import json
import glob
import re
import os

from utils import (
    fetch_speeches_from_db,
    update_summary_in_db,
    get_unprocessed_debate_ids
)

from concurrent.futures import ThreadPoolExecutor


import signal
import sys
import threading

import time

shutdown_event = threading.Event()

def handle_interrupt(signum, frame):
    print("\nğŸ›‘ Ctrl+C detected! Stopping new tasks...")
    shutdown_event.set()

signal.signal(signal.SIGINT, handle_interrupt)


# FastAPI endpoint
ec2_ip = "54.76.129.50"
url = f"http://{ec2_ip}:8000/api/generate"
username = "anotrandom-EMP-USER"
password = "EMP-EC2_123_TEXT_PROC"


def preprocess_text(text):
    """Remove irrelevant sections like ÎÎ¿Î¼Î¹ÎºÎ® Î¹ÏƒÏ‡ÏÏ‚ and Î¥Ï€Î¿Î³ÏÎ±Ï†Î­Ï‚."""
    patterns = [
            r'\s+',                                     # Normalize whitespace
    ]
    cleaned_text = text
    for pattern in patterns:
        cleaned_text = re.sub(pattern, ' ', cleaned_text, flags=re.DOTALL | re.IGNORECASE)
    return cleaned_text.strip()



def summarize_chunk(chunk, chunk_index, total_chunks):
    """Summarize a single chunk with context-aware prompt."""
    thread_id = threading.get_ident()
    start_time = time.time()
    print(f"ğŸ§µ Thread {thread_id} summarizing chunk {chunk_index+1}/{total_chunks}")

    prompt = f"""
    Î”Î·Î¼Î¹Î¿ÏÏÎ³Î·ÏƒÎµ Î¼Î¹Î± Ï€ÎµÏÎ¯Î»Î·ÏˆÎ· 100-150 Î»Î­Î¾ÎµÏ‰Î½ Î³Î¹Î± Ï„Î¿ Î±ÎºÏŒÎ»Î¿Ï…Î¸Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿, Ï€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Ï„Î¼Î®Î¼Î± {chunk_index+1} Î±Ï€ÏŒ {total_chunks} ÎµÎ½ÏŒÏ‚ Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿Ï… ÎµÎ³Î³ÏÎ¬Ï†Î¿Ï…:
    - Î•ÏƒÏ„Î¯Î±ÏƒÎµ ÏƒÏ„Î± ÎºÏÏÎ¹Î± ÏƒÎ·Î¼ÎµÎ¯Î±, Î±Ï€Î¿Ï†ÎµÏÎ³Î¿Î½Ï„Î±Ï‚ Î´ÎµÏ…Ï„ÎµÏÎµÏÎ¿Ï…ÏƒÎµÏ‚ Î»ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚.
    - Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï†Ï…ÏƒÎ¹ÎºÎ® ÎµÎ»Î»Î·Î½Î¹ÎºÎ® Î³Î»ÏÏƒÏƒÎ±, Ï‡Ï‰ÏÎ¯Ï‚ ÎµÏ€Î±Î½Î±Î»Î®ÏˆÎµÎ¹Ï‚.
    - ÎœÎ·Î½ Î±Î½Î±Ï†Î­ÏÎµÎ¹Ï‚ ÏŒÏ„Î¹ Ï€ÏÏŒÎºÎµÎ¹Ï„Î±Î¹ Î³Î¹Î± Î¼ÎµÏÎ¹ÎºÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î® ÏŒÏ„Î¹ ÎµÎ¯Î½Î±Î¹ Î±Ï€ÏŒ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Ï„Î¼Î®Î¼Î±.
    ÎšÎµÎ¯Î¼ÎµÎ½Î¿:
    {chunk}
    """
    payload = {
        "model": "krikri-summarizer",
        "prompt": prompt,
        "stream": False,
        "options": {"num_ctx": 32768}
    }
    response = requests.post(url, json=payload, auth=(username, password))
    response.raise_for_status()
    summary = json.loads(response.text)["response"]

    duration = time.time() - start_time
    print(f"â±ï¸ Thread {thread_id} finished chunk {chunk_index+1} in {duration:.2f}s")
    return summary



def combine_summaries(summaries):
    """Recursively summarize combined chunk summaries."""
    combined_text = ' '.join(summaries)

    # If summary-set is too long, we need to re-chunk
    if len(combined_text) > 15000:
        print("Too long â€” recursively summarizing summaries")
        return summarize_text(combined_text, source_name="recursive")

    prompt = f"""
    Î”Î·Î¼Î¹Î¿ÏÏÎ³Î·ÏƒÎµ Î¼Î¹Î± Ï„ÎµÎ»Î¹ÎºÎ® Ï€ÎµÏÎ¯Î»Î·ÏˆÎ· 100-150 Î»Î­Î¾ÎµÏ‰Î½ Î±Ï€ÏŒ Ï„Î¹Ï‚ Î±ÎºÏŒÎ»Î¿Ï…Î¸ÎµÏ‚ ÎµÏ€Î¹Î¼Î­ÏÎ¿Ï…Ï‚ Ï€ÎµÏÎ¹Î»Î®ÏˆÎµÎ¹Ï‚, Ï€Î¿Ï… ÎºÎ±Î»ÏÏ€Ï„Î¿Ï…Î½ Î­Î½Î± Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿ Î­Î³Î³ÏÎ±Ï†Î¿:
    - Î£Ï…Î½Î´ÏÎ±ÏƒÎµ Ï„Î± ÎºÏÏÎ¹Î± ÏƒÎ·Î¼ÎµÎ¯Î± ÏƒÎµ Î¼Î¹Î± ÎµÎ½Î¹Î±Î¯Î±, ÏƒÏ…Î½Î¿Ï€Ï„Î¹ÎºÎ® Ï€ÎµÏÎ¯Î»Î·ÏˆÎ·.
    - Î‘Ï†Î±Î¯ÏÎµÏƒÎµ ÎµÏ€Î±Î½Î±Î»Î®ÏˆÎµÎ¹Ï‚ ÎºÎ±Î¹ Î´ÎµÏ…Ï„ÎµÏÎµÏÎ¿Ï…ÏƒÎµÏ‚ Î»ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚.
    - Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï†Ï…ÏƒÎ¹ÎºÎ®, ÏÎ¿ÏŠÎºÎ® ÎµÎ»Î»Î·Î½Î¹ÎºÎ® Î³Î»ÏÏƒÏƒÎ±.
    - Î‘Î³Î½ÏŒÎ·ÏƒÎµ Ï„Ï…Ï‡ÏŒÎ½ Î±Î½Î±Ï†Î¿ÏÎ­Ï‚ ÏƒÎµ Î¼ÎµÏÎ¹ÎºÎ¬ ÎºÎµÎ¯Î¼ÎµÎ½Î± Î® Ï„Î¼Î®Î¼Î±Ï„Î±.
    Î ÎµÏÎ¹Î»Î®ÏˆÎµÎ¹Ï‚:
    {combined_text}
    """
    payload = {
        "model": "krikri-summarizer",
        "prompt": prompt,
        "stream": False,
        "options": {"num_ctx": 32768}
    }
    response = requests.post(url, json=payload, auth=(username, password))
    response.raise_for_status()
    final_summary = json.loads(response.text)["response"]
    return final_summary




def summarize_text(text, source_name="text"):
    """Summarize text using recursive summarization with overlap."""
    # Preprocess to remove irrelevant sections
    cleaned_text = preprocess_text(text)
    
    # Parameters
    chunk_size = 15000  # ~9k Greek words, within 32k tokens
    overlap_size = 2000  # ~1k Greek words, ensures context continuity
    
    if len(cleaned_text) <= chunk_size:
        prompt = f"""
        Î”Î·Î¼Î¹Î¿ÏÏÎ³Î·ÏƒÎµ Î¼Î¹Î± Ï€ÎµÏÎ¯Î»Î·ÏˆÎ· 100-150 Î»Î­Î¾ÎµÏ‰Î½:
        - Î•ÏƒÏ„Î¯Î±ÏƒÎµ ÏƒÏ„Î± ÎºÏÏÎ¹Î± ÏƒÎ·Î¼ÎµÎ¯Î±, Î±Ï€Î¿Ï†ÎµÏÎ³Î¿Î½Ï„Î±Ï‚ Î´ÎµÏ…Ï„ÎµÏÎµÏÎ¿Ï…ÏƒÎµÏ‚ Î»ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚.
        - Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï†Ï…ÏƒÎ¹ÎºÎ® ÎµÎ»Î»Î·Î½Î¹ÎºÎ® Î³Î»ÏÏƒÏƒÎ±, Ï‡Ï‰ÏÎ¯Ï‚ ÎµÏ€Î±Î½Î±Î»Î®ÏˆÎµÎ¹Ï‚.
        ÎšÎµÎ¯Î¼ÎµÎ½Î¿:
        {cleaned_text}
        """
        payload = {
            "model": "krikri-summarizer",
            "prompt": prompt,
            "stream": False,
            "options": {"num_ctx": 32768}
        }
        response = requests.post(url, json=payload, auth=(username, password))
        response.raise_for_status()
        summary = json.loads(response.text)["response"]
        print(f"Summary for {source_name}:\n{summary}")
        return summary
    
    # Chunk with overlap
    chunks = []
    for i in range(0, len(cleaned_text), chunk_size - overlap_size):
        chunk = cleaned_text[i:i + chunk_size]
        if chunk.strip():
            chunks.append(chunk)
    
    # Summarize each chunk
    chunk_summaries = []
    for idx, chunk in enumerate(chunks):
        summary = summarize_chunk(chunk, idx, len(chunks))
        chunk_summaries.append(summary)
    
    # Recursively summarize combined summaries
    final_summary = combine_summaries(chunk_summaries)
    print(f"Final summary for {source_name}:\n{final_summary}")
    return final_summary




import threading

progress_lock = threading.Lock()
progress_counter = {"done": 0, "total": 0}

def process_debate(debate_id, db_path, index, total):
    thread_id = threading.get_ident()
    start_time = time.time()
    try:
        print(f"[{debate_id}] ğŸ§  Started by thread {thread_id} | Debate {index}/{total}")
        text, count = fetch_speeches_from_db(db_path, debate_id)
        if not text.strip():
            print(f"[{debate_id}] âš ï¸ Empty valuable speeches.")
        else:
            summary = summarize_text(text, source_name=f"debate-{debate_id}")
            update_summary_in_db(db_path, debate_id, summary)
            duration = time.time() - start_time
            print(f"[{debate_id}] âœ… Summary complete in {duration:.2f}s by thread {thread_id}")
    except Exception as e:
        print(f"[{debate_id}] âŒ ERROR: {e}")
    finally:
        with progress_lock:
            progress_counter["done"] += 1
            print(f"ğŸ“Š Progress: {progress_counter['done']}/{total} debates complete.")




# === MAIN SCRIPT ===
if __name__ == "__main__":
    base_dir = os.path.dirname(__file__)
    DB_PATH = os.path.join(base_dir, "..", "strapi-app", ".tmp", "data.db")

    debate_ids = get_unprocessed_debate_ids(DB_PATH)
    total = len(debate_ids)
    progress_counter["total"] = total

    print(f"ğŸ”„ Starting parallel summarization of {total} debates...")

    with ThreadPoolExecutor(max_workers=5) as executor:
        for i, debate_id in enumerate(debate_ids, start=1):
            if shutdown_event.is_set():
                print("ğŸ›‘ Skipping remaining tasks due to shutdown.")
                break
            executor.submit(process_debate, debate_id, DB_PATH, i, total)